# @package _group_

# common trainer flags shared by all

_target_: pytorch_lightning.Trainer

max_epochs: 500
sync_batchnorm: True
weights_summary: top
flush_logs_every_n_steps: 50
num_sanity_val_steps: 2
resume_from_checkpoint: null # the checkpoint path will be overwritten if `config.restore` is true
