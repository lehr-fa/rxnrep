{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the NREL BDE dataset \n",
    "\n",
    "https://chemrxiv.org/articles/Prediction_of_Homolytic_Bond_Dissociation_Enthalpies_for_Organic_Molecules_at_near_Chemical_Accuracy_with_Sub-Second_Computational_Cost/10052048/2\n",
    "\n",
    "- add atom map number to the one bond break reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "from rxnrep.core.molecule import MoleculeError\n",
    "from rxnrep.core.reaction import ReactionError, smiles_to_reaction\n",
    "from rxnrep.data.grapher import (\n",
    "    get_atom_distance_to_reaction_center,\n",
    "    get_bond_distance_to_reaction_center,\n",
    ")\n",
    "from rxnrep.core.utils import generate_atom_map_number_one_bond_break_reaction\n",
    "from rxnrep.utils import to_path\n",
    "\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)  # supress rdkit warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(data: List, val_ratio=0.1, test_ratio=0.1, random_seed=35):\n",
    "    \"\"\"\n",
    "    Randomly split dataset into training, validation, and test test.\n",
    "    \"\"\"\n",
    "    assert val_ratio + test_ratio < 1.0, \"validation + test >= 1\"\n",
    "    size = len(data)\n",
    "    num_val = int(size * val_ratio)\n",
    "    num_test = int(size * test_ratio)\n",
    "    num_train = size - num_val - num_test\n",
    "\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    idx = np.random.permutation(size)\n",
    "    train_idx = idx[:num_train]\n",
    "    val_idx = idx[num_train : num_train + num_val]\n",
    "    test_idx = idx[num_train + num_val :]\n",
    "\n",
    "    train_set = [data[i] for i in train_idx]\n",
    "    val_set = [data[i] for i in val_idx]\n",
    "    test_set = [data[i] for i in test_idx]\n",
    "\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convert_to_mp_core_reaction(smi_rxn):\n",
    "    \"\"\"\n",
    "    Check whether a smile reaction can be converted to core reaction.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        rxn = smiles_to_reaction(\n",
    "            smi_rxn,\n",
    "            id=smi_rxn,\n",
    "            ignore_reagents=True,\n",
    "            remove_H=False,\n",
    "            sanity_check=False,\n",
    "        )\n",
    "\n",
    "        rxn.check_charge()\n",
    "        rxn.check_composition()\n",
    "        rxn.check_atom_map_number()\n",
    "\n",
    "    except (MoleculeError, ReactionError) as e:\n",
    "        return None, \"Fail converting to core reaction: \" + str(e)\n",
    "\n",
    "    # check we can get labels\n",
    "    try:\n",
    "        get_atom_distance_to_reaction_center(rxn)\n",
    "        get_bond_distance_to_reaction_center(rxn)\n",
    "    except AssertionError as e:\n",
    "        return None, \"Fail converting to core reaction: \" + str(e)\n",
    "\n",
    "    return {\"smi_rxn\": smi_rxn, \"core_rxn\": rxn}, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(reactions, reaction_ids, func, nprocs=1):\n",
    "    \"\"\"\n",
    "    Run with multiprocess.\n",
    "    \"\"\"\n",
    "    if nprocs == 1:\n",
    "        processed_rxns = [func(rxn) for rxn in reactions]\n",
    "    else:\n",
    "        with multiprocessing.Pool(nprocs) as p:\n",
    "            processed_rxns = p.map(func, reactions)\n",
    "\n",
    "    succeeded = []\n",
    "    succeeded_ids = []\n",
    "    failed = []\n",
    "    failed_ids = []\n",
    "    for i, (value, error) in enumerate(processed_rxns):\n",
    "        iid = reaction_ids[i]\n",
    "\n",
    "        if error is not None:\n",
    "            failed.append(error)\n",
    "            failed_ids.append(iid)\n",
    "        else:\n",
    "            succeeded.append(value)\n",
    "            succeeded_ids.append(iid)\n",
    "\n",
    "    return succeeded, succeeded_ids, failed, failed_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read smiles reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Read smiles reactions, activation energy and reaction enthalpy.\n",
    "    \"\"\"\n",
    "\n",
    "    # read smiles reactions\n",
    "    df = pd.read_csv(filename, header=0, index_col=None)\n",
    "\n",
    "    # remove duplicate reactions (i.e. with the same reactants and products)\n",
    "    unique_rxns = []\n",
    "    pd_serials = []\n",
    "    for idx, row in df.iterrows():\n",
    "        rxn = (row[\"molecule\"], tuple(sorted([row[\"fragment1\"], row[\"fragment2\"]])))\n",
    "        if rxn not in unique_rxns:\n",
    "            unique_rxns.append(rxn)\n",
    "            pd_serials.append(row)\n",
    "    df = pd.DataFrame(pd_serials)\n",
    "\n",
    "    df[\"reaction\"] = df[\"molecule\"] + \">>\" + df[\"fragment1\"] + \".\" + df[\"fragment2\"]\n",
    "\n",
    "    reactions = df[\"reaction\"].to_list()\n",
    "    bdes = df[\"bde\"].to_list()\n",
    "\n",
    "    return reactions, bdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCCCC(=O)O>>[CH2]CCC(=O)O.[NH2]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"/Users/mjwen/Documents/Dataset/NREL_BDE/rdf_data_190531_n200.csv\"\n",
    "# filename = \"/Users/mjwen/Documents/Dataset/NREL_BDE/rdf_data_190531.csv\"\n",
    "\n",
    "path = to_path(filename)\n",
    "smiles_rxns, bdes = read_file(filename)\n",
    "reaction_ids = list(range(len(smiles_rxns)))\n",
    "\n",
    "smiles_rxns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate atom map number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number succeeded: 128\n",
      "number failed: 0\n"
     ]
    }
   ],
   "source": [
    "def gen_atom_mapping(smiles_rxn):\n",
    "    try:\n",
    "        s = generate_atom_map_number_one_bond_break_reaction(smiles_rxn, add_H=True)\n",
    "        error = None\n",
    "    except Exception as e:\n",
    "        s = None\n",
    "        error = str(e)\n",
    "    return s, error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method(\"fork\", force=True)\n",
    "\n",
    "    succeeded0, succeeded0_ids, failed0, failed0_ids = runner(\n",
    "        smiles_rxns,\n",
    "        reaction_ids,\n",
    "        gen_atom_mapping,\n",
    "        nprocs=4,\n",
    "    )\n",
    "\n",
    "print(\"number succeeded:\", len(succeeded0))\n",
    "print(\"number failed:\", len(failed0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check reactions by convering to core Reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number succeeded: 127\n",
      "number failed: 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method(\"fork\", force=True)\n",
    "\n",
    "    succeeded1, succeeded1_ids, failed1, failed1_ids = runner(\n",
    "        succeeded0,\n",
    "        succeeded0_ids,\n",
    "        check_convert_to_mp_core_reaction,\n",
    "        nprocs=4,\n",
    "    )\n",
    "\n",
    "print(\"number succeeded:\", len(succeeded1))\n",
    "print(\"number failed:\", len(failed1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = failed0 + failed1\n",
    "failed_ids = failed0_ids + failed1_ids\n",
    "\n",
    "succeeded = []\n",
    "for rxn, i in zip(succeeded1, succeeded1_ids):\n",
    "    succeeded.append({\"smi_rxn\": rxn[\"smi_rxn\"], \"core_rxn\": rxn[\"core_rxn\"], \"idx\": i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write succeeded (with original smi input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path.parent.joinpath(path.stem + \"_succeeded\" + path.suffix)\n",
    "with open(fname, \"w\") as f:\n",
    "    f.write(\"index\\toriginal_reaction\\tcanonical_reaction\\n\")\n",
    "    for x in succeeded:\n",
    "        i = x[\"idx\"]\n",
    "        f.write(f\"{i}\\t{smiles_rxns[i]}\\t{x['smi_rxn']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write failed (with original smi input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path.parent.joinpath(path.stem + \"_failed\" + path.suffix)\n",
    "with open(fname, \"w\") as f:\n",
    "    f.write(\"index\\toriginal_reaction\\terror\\n\")\n",
    "    for i, error in zip(failed_ids, failed):\n",
    "        f.write(f\"{i}\\t{smiles_rxns[i]}\\t{error}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write dataset for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_for_training(\n",
    "    data: List, reaction_energy: List, fname\n",
    "):\n",
    "    \"\"\"Write dataset to tsv.\"\"\"\n",
    "    smiles = []\n",
    "    raw_id = []\n",
    "    energy = []\n",
    "    for x in data:\n",
    "        i = x[\"idx\"]\n",
    "        raw_id.append(i)\n",
    "        smiles.append(x[\"smi_rxn\"])\n",
    "        energy.append(reaction_energy[i])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"reaction\": smiles,\n",
    "            \"reaction energy\": energy,\n",
    "            \"raw id\": raw_id,\n",
    "        }\n",
    "    )\n",
    "    df.to_csv(fname, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset for training\n",
    "\n",
    "train_set, val_set, test_set = split_train_val_test(succeeded)\n",
    "\n",
    "tr_fname = path.parent.joinpath(path.stem + \"_processed_train.tsv\")\n",
    "write_dataset_for_training(train_set,bdes, tr_fname)\n",
    "\n",
    "val_fname = path.parent.joinpath(path.stem + \"_processed_val.tsv\")\n",
    "write_dataset_for_training(val_set, bdes, val_fname)\n",
    "\n",
    "te_fname = path.parent.joinpath(path.stem + \"_processed_test.tsv\")\n",
    "write_dataset_for_training(test_set, bdes, te_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
