{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Grambow-Green activation dataset \n",
    "\n",
    "data from: https://zenodo.org/record/3715478#.XuAZxC3MxTY\n",
    "\n",
    "paper describing the data: https://doi.org/10.1038/s41597-020-0460-4\n",
    "paper using the data: J. Phys. Chem. Lett. 2020, 11, 2992âˆ’2997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "from rxnrep.core.molecule import MoleculeError\n",
    "from rxnrep.core.reaction import ReactionError, smiles_to_reaction\n",
    "from rxnrep.data.grapher import (\n",
    "    get_atom_distance_to_reaction_center,\n",
    "    get_bond_distance_to_reaction_center,\n",
    ")\n",
    "from rxnrep.utils import to_path\n",
    "\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)  # supress rdkit warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smiles_reaction(reaction, filename):\n",
    "    \"\"\"\n",
    "    Plot a smiles reaction to file.\n",
    "    \"\"\"\n",
    "    rxn = AllChem.ReactionFromSmarts(reaction, useSmiles=True)\n",
    "    image = Chem.Draw.ReactionToImage(rxn)\n",
    "    image.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(data: List, val_ratio=0.1, test_ratio=0.1, random_seed=35):\n",
    "    \"\"\"\n",
    "    Randomly split dataset into training, validation, and test test.\n",
    "    \"\"\"\n",
    "    assert val_ratio + test_ratio < 1.0, \"validation + test >= 1\"\n",
    "    size = len(data)\n",
    "    num_val = int(size * val_ratio)\n",
    "    num_test = int(size * test_ratio)\n",
    "    num_train = size - num_val - num_test\n",
    "\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    idx = np.random.permutation(size)\n",
    "    train_idx = idx[:num_train]\n",
    "    val_idx = idx[num_train : num_train + num_val]\n",
    "    test_idx = idx[num_train + num_val :]\n",
    "\n",
    "    train_set = [data[i] for i in train_idx]\n",
    "    val_set = [data[i] for i in val_idx]\n",
    "    test_set = [data[i] for i in test_idx]\n",
    "\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convert_to_mp_core_reaction(smi_rxn):\n",
    "    \"\"\"\n",
    "    Check whether a smile reaction can be converted to core reaction.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        rxn = smiles_to_reaction(\n",
    "            smi_rxn,\n",
    "            id=smi_rxn,\n",
    "            ignore_reagents=True,\n",
    "            remove_H=False,\n",
    "            sanity_check=False,\n",
    "        )\n",
    "\n",
    "        rxn.check_charge()\n",
    "        rxn.check_composition()\n",
    "        rxn.check_atom_map_number()\n",
    "\n",
    "    except (MoleculeError, ReactionError) as e:\n",
    "        return None, \"Fail converting to core reaction: \" + str(e)\n",
    "\n",
    "    # check we can get labels\n",
    "    try:\n",
    "        get_atom_distance_to_reaction_center(rxn)\n",
    "        get_bond_distance_to_reaction_center(rxn)\n",
    "    except AssertionError as e:\n",
    "        return None, \"Fail converting to core reaction: \" + str(e)\n",
    "\n",
    "    return {\"smi_rxn\": smi_rxn, \"core_rxn\": rxn}, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(reactions, reaction_ids, func, nprocs=1):\n",
    "    \"\"\"\n",
    "    Run with multiprocess. \n",
    "    \"\"\"\n",
    "    if nprocs == 1:\n",
    "        processed_rxns = [func(rxn) for rxn in reactions]\n",
    "    else:\n",
    "        with multiprocessing.Pool(nprocs) as p:\n",
    "            processed_rxns = p.map(func, reactions)\n",
    "\n",
    "    succeeded = []\n",
    "    succeeded_ids = []\n",
    "    failed = []\n",
    "    failed_ids = []\n",
    "    for i, (value, error) in enumerate(processed_rxns):\n",
    "        iid = reaction_ids[i]\n",
    "\n",
    "        if error is not None:\n",
    "            failed.append(error)\n",
    "            failed_ids.append(iid)\n",
    "        else:\n",
    "            succeeded.append(value)\n",
    "            succeeded_ids.append(iid)\n",
    "\n",
    "    return succeeded, succeeded_ids, failed, failed_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read smiles reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, include_reverse=False):\n",
    "    \"\"\"\n",
    "    Read smiles reactions, activation energy and reaction enthalpy. \n",
    "    \"\"\"\n",
    "\n",
    "    # read smiles reactions\n",
    "    df = pd.read_csv(filename, header=0, index_col=0)\n",
    "\n",
    "    reactants = df[\"rsmi\"].tolist()\n",
    "    products = df[\"psmi\"].tolist()\n",
    "    activation_energy = df[\"ea\"].tolist()\n",
    "    reaction_enthalpy = df[\"dh\"].tolist()\n",
    "\n",
    "    smiles_rxns = [f\"{r}>>{p}\" for r, p in zip(reactants, products)]\n",
    "    \n",
    "    if include_reverse:\n",
    "        smiles_rxns += [f\"{p}>>{r}\" for r, p in zip(reactants, products)]\n",
    "        activation_energy += [a-r for a,r in zip(activation_energy, reaction_enthalpy)]\n",
    "        reaction_enthalpy += [-x for x in reaction_enthalpy]\n",
    "\n",
    "    return smiles_rxns, activation_energy, reaction_enthalpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename = \"/Users/mjwen/Documents/Dataset/activation_energy_Green/b97d3.csv\"\n",
    "filename = \"/Users/mjwen/Documents/Dataset/activation_energy_Green/wb97xd3.csv\"\n",
    "# filename = \"/Users/mjwen/Documents/Dataset/activation_energy_Green/wb97xd3_n200.csv\"\n",
    "\n",
    "path = to_path(filename)\n",
    "smiles_rxns, activation_energy, reaction_enthalpy = read_file(filename, include_reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check reactions by convering to core Reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number succeeded: 23906\n",
      "number failed: 16\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method(\"fork\", force=True)\n",
    "\n",
    "    reaction_ids = list(range(len(smiles_rxns)))\n",
    "    succeeded1, succeeded1_ids, failed1, failed1_ids = runner(\n",
    "        smiles_rxns, reaction_ids, check_convert_to_mp_core_reaction, nprocs=4,\n",
    "    )\n",
    "\n",
    "print(\"number succeeded:\", len(succeeded1))\n",
    "print(\"number failed:\", len(failed1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = failed1\n",
    "failed_ids = failed1_ids\n",
    "\n",
    "succeeded = []\n",
    "for rxn, i in zip(succeeded1, succeeded1_ids):\n",
    "    succeeded.append({\"smi_rxn\": rxn[\"smi_rxn\"], \"core_rxn\": rxn[\"core_rxn\"], \"idx\": i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write succeeded (with original smi input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path.parent.joinpath(path.stem + \"_succeeded\" + path.suffix)\n",
    "with open(fname, \"w\") as f:\n",
    "    f.write(\"index\\toriginal_reaction\\tcanonical_reaction\\n\")\n",
    "    for x in succeeded:\n",
    "        i = x[\"idx\"]\n",
    "        f.write(f\"{i}\\t{smiles_rxns[i]}\\t{x['smi_rxn']}\\n\")\n",
    "\n",
    "#         # save iamge\n",
    "#         fname = fname = path.parent.joinpath('image', f'{i}_original' + '.png')\n",
    "#         plot_smiles_reaction(smiles_rxns[i], fname)\n",
    "#         fname = fname = path.parent.joinpath('image', f'{i}_edited' + '.png')\n",
    "#         plot_smiles_reaction(smi, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write failed (with original smi input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path.parent.joinpath(path.stem + \"_failed\" + path.suffix)\n",
    "with open(fname, \"w\") as f:\n",
    "    f.write(\"index\\toriginal_reaction\\terror\\n\")\n",
    "    for i, error in zip(failed_ids, failed):\n",
    "        f.write(f\"{i}\\t{smiles_rxns[i]}\\t{error}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write dataset for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_for_training(data: List, activation_energy: List, reaction_enthalpy:List, fname):\n",
    "    \"\"\"Write dataset to tsv.\"\"\"\n",
    "    smiles = []\n",
    "    raw_id = []\n",
    "    activation = []\n",
    "    enthalpy = []\n",
    "    for x in data:\n",
    "            i= x[\"idx\"]\n",
    "            raw_id.append(i)\n",
    "            smiles.append(x[\"smi_rxn\"])\n",
    "            activation.append(activation_energy[i])\n",
    "            enthalpy.append(reaction_enthalpy[i])\n",
    "\n",
    "    df = pd.DataFrame({'reaction':smiles, 'activation energy':activation, 'reaction enthalpy':enthalpy, 'raw id':raw_id})\n",
    "    df.to_csv(fname, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species(dataset):\n",
    "    \"\"\"Get the species in train/test/val dataset.\"\"\"\n",
    "    species = set()\n",
    "    for x in dataset:\n",
    "        rxn = x[\"core_rxn\"]\n",
    "        species.update(rxn.species)\n",
    "\n",
    "    return sorted(species)\n",
    "\n",
    "\n",
    "def remove_rare_rxn(dataset, species: List[str]):\n",
    "    \"\"\"\n",
    "    Remove rxn in dataset whose species are not in `species`. Typically `species` \n",
    "    is from the training set and `dataset` are test/val set. If some species are \n",
    "    not in the species of the training set, there are not so many of them and we \n",
    "    remove such reactions.\n",
    "    \"\"\"\n",
    "    species = set(species)\n",
    "    new_dataset = []\n",
    "    for x in dataset:\n",
    "        rxn = x[\"core_rxn\"]\n",
    "        if set(rxn.species).issubset(species):\n",
    "            new_dataset.append(x)\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset for training\n",
    "\n",
    "train_set, val_set, test_set = split_train_val_test(succeeded)\n",
    "\n",
    "tr_fname = path.parent.joinpath(path.stem + \"_processed_train.tsv\")\n",
    "write_dataset_for_training(train_set, activation_energy, reaction_enthalpy, tr_fname)\n",
    "\n",
    "val_fname = path.parent.joinpath(path.stem + \"_processed_val.tsv\")\n",
    "write_dataset_for_training(val_set,activation_energy, reaction_enthalpy, val_fname)\n",
    "\n",
    "te_fname = path.parent.joinpath(path.stem + \"_processed_test.tsv\")\n",
    "write_dataset_for_training(test_set,activation_energy, reaction_enthalpy, te_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
