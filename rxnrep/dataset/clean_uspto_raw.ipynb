{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the raw USPTO dataset \n",
    "\n",
    "The raw dataset can be obtained from https://doi.org/10.6084/m9.figshare.5104873  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple, List\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from rxnrep.dataset.uspto_utils import (\n",
    "    check_all_reactions_atom_mapped,\n",
    "    check_all_reactions_bonds_mapped,\n",
    "    adjust_reagents,\n",
    "    adjust_atom_map_number,\n",
    "    get_reaction_bond_change,\n",
    "    MoleculeCreationError,\n",
    "    AtomMapNumberError,\n",
    "    canonicalize_smiles_reaction,\n",
    "    canonicalize_smiles_reaction_by_adding_nonexist_atoms_and_bonds,\n",
    ")\n",
    "from rxnrep.data.grapher import (\n",
    "    get_atom_distance_to_reaction_center,\n",
    "    get_bond_distance_to_reaction_center,\n",
    ")\n",
    "from rxnrep.core.molecule import MoleculeError\n",
    "from rxnrep.core.reaction import smiles_to_reaction, ReactionError\n",
    "from rxnrep.utils import to_path\n",
    "\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)  # supress rdkit warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smiles_reaction(reaction, filename):\n",
    "    \"\"\"\n",
    "    Plot a smiles reaction to file.\n",
    "    \"\"\"\n",
    "    rxn = AllChem.ReactionFromSmarts(reaction, useSmiles=True)\n",
    "    image = Chem.Draw.ReactionToImage(rxn)\n",
    "    image.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(data: List, val_ratio=0.1, test_ratio=0.1, random_seed=35):\n",
    "    \"\"\"\n",
    "    Split dataset into training, validation, and test test.\n",
    "    \"\"\"\n",
    "    assert val_ratio + test_ratio < 1.0, \"validation + test >= 1\"\n",
    "    size = len(data)\n",
    "    num_val = int(size * val_ratio)\n",
    "    num_test = int(size * test_ratio)\n",
    "    num_train = size - num_val - num_test\n",
    "\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    idx = np.random.permutation(size)\n",
    "    train_idx = idx[:num_train]\n",
    "    val_idx = idx[num_train : num_train + num_val]\n",
    "    test_idx = idx[num_train + num_val :]\n",
    "\n",
    "    train_set = [data[i] for i in train_idx]\n",
    "    val_set = [data[i] for i in val_idx]\n",
    "    test_set = [data[i] for i in test_idx]\n",
    "\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convert_to_mp_core_reaction(smi_rxn):\n",
    "    \"\"\"\n",
    "    Check whether a smile reaction can be converted to core reaction.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        rxn = smiles_to_reaction(\n",
    "            smi_rxn, smi_rxn, ignore_reagents=True, sanity_check=False\n",
    "        )\n",
    "        # rxn.check_charge()  # we ignore the ones (it does not matter since we do not use charge in the feature)\n",
    "        rxn.check_composition()\n",
    "        rxn.check_atom_map_number()\n",
    "    except (MoleculeError, ReactionError) as e:\n",
    "        return None, \"Fail converting to core reaction: \" + str(e)\n",
    "\n",
    "    # check we can get labels\n",
    "    try:\n",
    "        get_atom_distance_to_reaction_center(rxn)\n",
    "        get_bond_distance_to_reaction_center(rxn)\n",
    "    except AssertionError as e:\n",
    "        return None, \"Fail converting to core reaction: \" + str(e)\n",
    "\n",
    "    return {\"smi_rxn\": smi_rxn, \"core_rxn\": rxn}, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(reactions, reaction_ids, func, nprocs=1):\n",
    "    \"\"\"\n",
    "    Run with multiprocess. \n",
    "    \"\"\"\n",
    "    if nprocs == 1:\n",
    "        processed_rxns = [func(rxn) for rxn in reactions]\n",
    "    else:\n",
    "        with multiprocessing.Pool(nprocs) as p:\n",
    "            processed_rxns = p.map(func, reactions)\n",
    "\n",
    "    succeeded = []\n",
    "    succeeded_ids = []\n",
    "    failed = []\n",
    "    failed_ids = []\n",
    "    for i, (value, error) in enumerate(processed_rxns):\n",
    "        iid = reaction_ids[i]\n",
    "\n",
    "        if error is not None:\n",
    "            failed.append(error)\n",
    "            failed_ids.append(iid)\n",
    "        else:\n",
    "            succeeded.append(value)\n",
    "            succeeded_ids.append(iid)\n",
    "\n",
    "    return succeeded, succeeded_ids, failed, failed_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read smiles reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Read smiles reactions and labels. \n",
    "    \"\"\"\n",
    "    # read smiles reactions\n",
    "    df = pd.read_csv(filename, sep=\"\\t\")\n",
    "    smiles_rxns = df[\"ReactionSmiles\"].values.tolist()\n",
    "    # remove the part in f||, like f|0.1.2|\n",
    "    smiles_rxns = [s.split()[0] for s in smiles_rxns]\n",
    "\n",
    "    return smiles_rxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/Users/mjwen/Documents/Dataset/uspto/raw/2001_Sep2016_USPTOapplications_smiles.rsmi\"\n",
    "# filename = \"/Users/mjwen/Documents/Dataset/uspto/raw/2001_Sep2016_USPTOapplications_smiles_n200.rsmi\"\n",
    "filename = \"/Users/mjwen/Documents/Dataset/uspto/raw/2001_Sep2016_USPTOapplications_smiles_n200.rsmi\"\n",
    "\n",
    "path = to_path(filename)\n",
    "smiles_rxns = read_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonicalize the reactions (first check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number succeeded: 181\n",
      "number failed: 20\n"
     ]
    }
   ],
   "source": [
    "# NOTE, python 3.8 multiprocessing default to spawn to create process on macOS.\n",
    "# this does not work in Jupyter. So set it to `fork`.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method(\"fork\", force=True)\n",
    "\n",
    "    reaction_ids = list(range(len(smiles_rxns)))\n",
    "    succeeded1, succeeded1_ids, failed1, failed1_ids = runner(\n",
    "        smiles_rxns,\n",
    "        reaction_ids,\n",
    "        canonicalize_smiles_reaction_by_adding_nonexist_atoms_and_bonds,\n",
    "        nprocs=4,\n",
    "    )\n",
    "\n",
    "print(\"number succeeded:\", len(succeeded1))\n",
    "print(\"number failed:\", len(failed1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whether can convert to core reactions (second check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number succeeded: 181\n",
      "number failed: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method(\"fork\", force=True)\n",
    "\n",
    "    succeeded2, succeeded2_ids, failed2, failed2_ids = runner(\n",
    "        succeeded1, succeeded1_ids, check_convert_to_mp_core_reaction, nprocs=4,\n",
    "    )\n",
    "\n",
    "print(\"number succeeded:\", len(succeeded2))\n",
    "print(\"number failed:\", len(failed2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = failed1 + failed2\n",
    "failed_ids = failed1_ids + failed2_ids\n",
    "\n",
    "succeeded = []\n",
    "for rxn, i in zip(succeeded2, succeeded2_ids):\n",
    "    succeeded.append({\"smi_rxn\": rxn[\"smi_rxn\"], \"core_rxn\": rxn[\"core_rxn\"], \"idx\": i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write succeeded (with original smi input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path.parent.joinpath(path.stem + \"_succeeded\" + path.suffix)\n",
    "with open(fname, \"w\") as f:\n",
    "    f.write(\"index\\toriginal_reaction\\tcanonical_reaction\\n\")\n",
    "    for x in succeeded:\n",
    "        i = x[\"idx\"]\n",
    "        f.write(f\"{i}\\t{smiles_rxns[i]}\\t{x['smi_rxn']}\\n\")\n",
    "        \n",
    "#         # save iamge\n",
    "#         fname = fname = path.parent.joinpath('image', f'{i}_original' + '.png')\n",
    "#         plot_smiles_reaction(smiles_rxns[i], fname)\n",
    "#         fname = fname = path.parent.joinpath('image', f'{i}_edited' + '.png')\n",
    "#         plot_smiles_reaction(smi, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write failed (with original smi input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path.parent.joinpath(path.stem + \"_failed\" + path.suffix)\n",
    "with open(fname, \"w\") as f:\n",
    "    f.write(\"index\\toriginal_reaction\\terror\\n\")\n",
    "    for i, error in zip(failed_ids, failed):\n",
    "        f.write(f\"{i}\\t{smiles_rxns[i]}\\t{error}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_for_training(data, fname):\n",
    "    with open(fname, \"w\") as f:\n",
    "        f.write(\"reaction\\tlabel\\traw id\\n\")\n",
    "        label = None\n",
    "        for x in data:\n",
    "            i = x[\"idx\"]\n",
    "            smi = x[\"smi_rxn\"]\n",
    "            f.write(f\"{smi}\\t{label}\\t{i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species(dataset):\n",
    "    \"\"\"Get the species in train/test/val dataset.\"\"\"\n",
    "    species = set()\n",
    "    for x in dataset:\n",
    "        rxn = x[\"core_rxn\"]\n",
    "        species.update(rxn.species)\n",
    "\n",
    "    return sorted(species)\n",
    "\n",
    "\n",
    "def remove_rare_rxn(dataset, species: List[str]):\n",
    "    \"\"\"\n",
    "    Remove rxn in dataset whose species are not in `species`. Typically `species` \n",
    "    is from the training set and `dataset` are test/val set. If some species are \n",
    "    not in the species of the training set, there are not so many of them and we \n",
    "    remove such reactions.\n",
    "    \"\"\"\n",
    "    species = set(species)\n",
    "    new_dataset = []\n",
    "    for x in dataset:\n",
    "        rxn = x[\"core_rxn\"]\n",
    "        if set(rxn.species).issubset(species):\n",
    "            new_dataset.append(x)\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset for training\n",
    "train_set, val_set, test_set = split_train_val_test(succeeded)\n",
    "train_set_species = get_species(train_set)\n",
    "val_set = remove_rare_rxn(val_set, train_set_species)\n",
    "test_set = remove_rare_rxn(test_set, train_set_species)\n",
    "\n",
    "tr_fname = path.parent.joinpath(path.stem + \"_processed_train.tsv\")\n",
    "write_dataset_for_training(train_set, tr_fname)\n",
    "\n",
    "val_fname = path.parent.joinpath(path.stem + \"_processed_val.tsv\")\n",
    "write_dataset_for_training(val_set, val_fname)\n",
    "\n",
    "te_fname = path.parent.joinpath(path.stem + \"_processed_test.tsv\")\n",
    "write_dataset_for_training(test_set, te_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
