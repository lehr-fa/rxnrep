# @package _group_

_target_: pytorch_lightning.Trainer

# common settings
weights_summary: top
flush_logs_every_n_steps: 50
num_sanity_val_steps: 2
sync_batchnorm: True
resume_from_checkpoint: null # this will be overwritten if `config.restore` is true

# special settings
max_epochs: 500
num_nodes: 1
gpus: 2
accelerator: ddp
